


pip install selenium


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time
options= Options()
options


options.add_experimental_option('detach',True)


url = 'https://naver.com'
driver = webdriver.Chrome(options=options)


driver.get(url)
time.sleep(2)


driver.back()


driver.forward()


driver.refresh()


driver.find_element?


driver.find_element(By.ID,'query')


driver.find_element(By.ID,'query').send_keys('뉴진스')


driver.find_element(By.CLASS_NAME,'search_input').send_keys('블랙핑크');


driver.find_element(By.NAME,'query').send_keys('르세라핌');


driver.find_element(By.CSS_SELECTOR,'#query').send_keys('에스파')


driver.find_element(By.CSS_SELECTOR,".search_input").send_keys("세븐틴")


driver.find_element(By.CSS_SELECTOR,"[title='검색어를 입력해 주세요.']").send_keys("트와이스")


#태그 우클릭, 카피 들을 하면 복사된다.


driver.find_element(By.XPATH,"//*[@id='query']").send_keys("BTS")


#네이퍼 쇼핑 메뉴를 클릭해 보자
driver.find_element(By.LINK_TEXT,'쇼핑').click()


driver.find_element(By.PARTIAL_LINK_TEXT,'증').click()


driver.find_element(By.TAG_NAME,'ul')


driver.find_elements(By.CSS_SELECTOR,'.link_service')


for i in driver.find_elements(By.CSS_SELECTOR,'.link_service'):
     print(i.get_dom_attribute('href'))


url = 'C://workspace/WASSUP4/02_Data_Collection/sample/signin.html'
driver = webdriver.Chrome(options=options)
driver.get(url)
time.sleep(2)


username = driver.find_element(By.NAME,'username')
username.send_keys('korea')
password = driver.find_element(By.NAME,'password')
password.send_keys('1234')


login = driver.find_element(By.XPATH,'//*[@id="loginForm"]/input[3]')
login.click()
time.sleep(1)


driver.back()


login = driver.find_element(By.CSS_SELECTOR,'[value=Login]')
login.click()


driver.back()


username = driver.find_element(By.NAME,'username')
username.clear()



username = driver.find_element(By.NAME,'username')
username.send_keys('korea')
password = driver.find_element(By.NAME,'password')
password.send_keys('1234')


username.submit()


driver.back()


driver.find_element(By.TAG_NAME,'p').text


driver.page_source


driver.close()


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time
options= Options()
options


options.add_argument("--headless=new")# colab 이용가능하게 하기,background

options.add_experimental_option('detach',True)


url = 'https://naver.com'
driver = webdriver.Chrome(options=options)


driver.get(url)
time.sleep(2)
print(driver.title)


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

options = Options()
# options.add_argument("--start-maximized")
# options.add_argument("--headless=new") 
options.add_experimental_option("detach", True) #

url = 'http://naver.com'
driver = webdriver.Chrome(options=options)
driver.get(url)
time.sleep(2)


driver.get_window_size()


driver.set_window_size(300,600)


position = driver.get_window_position()
x = position.get('x')
y = position.get('y')
print(x,y)


driver.set_window_position(0,0)



driver.minimize_window()


driver.fullscreen_window()


driver.save_screenshot('./image.png')


driver.quit()


#네이버, 인공지능 ,블로그, 옵션, 관련도순, 기간 2024.1.11~2024.9.27


#수집후 정렬



from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, random, pandas as pd

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)


driver = webdriver.Chrome( options = options)
# 조건 설정
where = 'blog'
query = '인공지능'
dateform = '20240101to20240927'
url = f'https://search.naver.com/search.naver?ssc=tab.{where}.all&query={query}&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom{dateform}'
# url = f'https://search.naver.com/search.naver?where={where}&query={query}&sm=tab_op&nso=so:r,p:from{dateform}'
fname = f'{where}_{query}_{dateform}'
# url 접속
driver.get(url)
time.sleep(random.randint(2,3))





#https://search.naver.com/search.naver?ssc=tab.blog.all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom20240101to202409227
#https://search.naver.com/search.naver?ssc=tab.blog.all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom20240101to20240927


for i in range(10):
    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')
    time.sleep(random.randint(2, 3))


# get_view()
views = driver.find_elements(By.CSS_SELECTOR, '.lst_view .view_wrap')
result = []

for view in views:
    con_dict = {}
    con_dict['title'] = view.find_element(By.CSS_SELECTOR, '.title_link').text
    con_dict['text'] = view.find_element(By.CSS_SELECTOR, '.dsc_link').text
    con_dict['date'] = view.find_element(By.CSS_SELECTOR, '.sub').text
    result.append(con_dict)
    print(con_dict)
    
print('완료')


print(result)


df = pd.DataFrame(result)
df


df.to_csv(f'output/naver_{fname}.csv', sep=',', encoding='utf-8-sig')


#여행기사, 296 , 컨텐츠 모두 이미지, 기사
#페이지 순환


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, random, pandas as pd

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)

driver = webdriver.Chrome( options = options)
url = 'https://play.google.com/store/apps/details?id=com.estsoft.picnic'
driver.get(url)
time.sleep(random.randint(2,3))


#xpath = '//*[@id="yDmH0d"]/c-wiz[2]/div/div/div[1]/div/div[2]/div/div[1]/div[1]/c-wiz[4]/section/div/div[2]/div[5]/div/div/button/span'
xpath = '/html/body/c-wiz[2]/div/div/div[1]/div/div[2]/div/div[1]/div[1]/c-wiz[5]/section/header/div/div[2]/button/i'
driver.find_element(By.XPATH, xpath).click()
time.sleep(random.randint(2, 3))
# 미리 스크롤해서 html정보 받아오기
for i in range(10):
    review_box = driver.find_element(By.CSS_SELECTOR, 'div.fysCi')
    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', review_box )
    time.sleep(random.randint(2, 3))


reviews = driver.find_elements(By.CSS_SELECTOR, 'div.RHo1pe')
reviews


for i in reviews:
    review = {}
    review['text'] = i.find_element(By.CSS_SELECTOR, '.h3YV2d').text
    review['star'] = len(i.find_elements(By.CSS_SELECTOR, '.F7XJmb'))
    review['date'] = i.find_element(By.CSS_SELECTOR, '.bp9Aid').text
    result.append(review)
    print(review)
# 요소별 추출
def get_content(review):
    condic = {}
    condic['text'] = review.find_element(By.CSS_SELECTOR, 'div.h3YV2d').text
    condic['rat'] = len(review.find_elements(By.CSS_SELECTOR, 'span.Z1Dz7b'))
    condic['date'] = review.find_element(By.CSS_SELECTOR, 'span.bp9Aid').text
    return condic
result = [get_content(review) for review in reviews]
df = pd.DataFrame(result)
df


df



